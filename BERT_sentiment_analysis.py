# -*- coding: utf-8 -*-
"""Model Training (fixed?).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sSe06mw9KnpiP1a5VCOqcXhu0ph1Oexs
"""

!pip install transformers torch

import torch
from transformers import pipeline
from tqdm import tqdm
import pandas as pd
from collections import defaultdict
import json
import re
import matplotlib.pyplot as plt
import seaborn as sns
import os

from google.colab import drive
drive.mount('/content/drive')

import os

dir = "/content/drive/MyDrive/thesis/Deployment"
os.listdir(dir)

import pandas as pd
import glob

csv_file_path = "/content/drive/MyDrive/thesis/Deployment"
data = glob.glob(f"{csv_file_path}/*.csv")

dfs = []
for f in data:
    df = pd.read_csv(f)
    df["source_file"] = os.path.basename(f)
    dfs.append(df)

df = pd.concat(dfs, ignore_index=True)

display(df.head())

review_counts = df.groupby('place_name')['review_id'].count().reset_index()
review_counts = review_counts.rename(columns={'review_id': 'review_count'})
display(review_counts.sort_values(by='review_count', ascending=False))

non_nan_reviews_per_place = df.groupby('place_name')['review_text'].apply(lambda x: x.notnull().sum()).reset_index()
non_nan_reviews_per_place = non_nan_reviews_per_place.rename(columns={'review_text': 'non_nan_review_count'})

nan_reviews_per_place = df.groupby('place_name')['review_text'].apply(lambda x: x.isnull().sum()).reset_index()
nan_reviews_per_place = nan_reviews_per_place.rename(columns={'review_text': 'nan_review_count'})

merged_review_counts = pd.merge(non_nan_reviews_per_place,
                                nan_reviews_per_place,
                                on='place_name',
                                how='left')

display(merged_review_counts.sort_values(by='non_nan_review_count', ascending=False))

df.info()

df = df.drop(columns=[
    'published_at',
    'response_from_owner_text',
    'response_from_owner_ago',
    'response_from_owner_date',
    'response_from_owner_translated_text',
    'avatar_link',
    'total_number_of_reviews_by_reviewer',
    'total_number_of_photos_by_reviewer',
    'is_local_guide',
    'review_photos',
    'review_origin'
], errors='ignore')

df.head()

output_path = '/content/drive/MyDrive/thesis/dataset.csv'
df.to_csv(output_path, index=False)

df = df.dropna(subset=['review_text'])

df.info()

df['published_at_date'].head(5)

df['published_at_date'] = df['published_at_date'].str.split('T').str[0]
df['published_at_date'] = pd.to_datetime(df['published_at_date'], format='%Y-%m-%d')

# Remove HTML, tags, excessive whitespaces
import re
def clean_text(text):
    text = re.sub(r'http\S+', '', text)
    text = re.sub(r'<.*?>', '', text)
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()
    return text

df["review_text"] = df["review_text"].apply(clean_text)

top_n = 5
data = df['place_name'].value_counts().head(top_n)

plt.figure(figsize=(9,5))
ax = sns.barplot(
    x=data.values,
    y=data.index
)

# Set x limit with padding
max_val = data.values.max()
plt.xlim(0, max_val * 1.15)

# Add value labels safely
for i, v in enumerate(data.values):
    ax.text(v + max_val*0.02, i, f"{v:,}", va='center', fontsize=10)

plt.title("Total of Cleaned Reviews", fontsize=14, weight='bold')
plt.xlabel("Number of Reviews", fontsize=11)
plt.ylabel("")
plt.grid(axis='x', linestyle='--', alpha=0.4)

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 6))
sns.countplot(data=df, x='rating', palette='viridis')
plt.title('Distribution of Ratings')
plt.xlabel('Rating')
plt.ylabel('Number of Reviews')
plt.show()

df['published_at_date'] = pd.to_datetime(df['published_at_date'])

# Count reviews per month
reviews_over_time = df.groupby(df['published_at_date'].dt.to_period("M")).size()

plt.figure(figsize=(10,4))
reviews_over_time.plot(kind='line', marker='o', color='teal')
plt.title("Reviews Over Time")
plt.xlabel("Month")
plt.ylabel("Number of Reviews")
plt.grid(True, alpha=0.3)
plt.show()

aspect_keywords = {
    'kursi_roda': [
        (r'kursi roda', 'kursi roda'),
        (r'wheelchair', 'wheelchair'),
        (r'roda\s*kursi', 'kursi roda'),
        (r'stroller', 'stroller'),
        (r'kereta bayi', 'kereta bayi'),
        (r'kereta dorong', 'kereta dorong'),
        (r'baby stroller', 'stroller'),
        (r'pushchair', 'stroller'),
        # Additional wheelchair-specific terms
        (r'mobility\s*(aid|device|equipment)', 'mobility aid'),
        (r'alat\s*bantu\s*(jalan|gerak)', 'alat bantu gerak'),
        (r'walker', 'walker'),
        (r'rollator', 'rollator'),
        (r'tongkat\s*(jalan|kaki)', 'tongkat jalan'),
        (r'kruk', 'kruk'),
        (r'crutches', 'crutches'),
        (r'electric\s*wheelchair', 'electric wheelchair'),
        (r'kursi\s*roda\s*(listrik|elektrik)', 'kursi roda listrik'),
        (r'scooter\s*(mobility|disabled)', 'mobility scooter'),
    ],

    'disabilitas': [
        (r'disabilitas', 'disabilitas'),
        (r'difabel', 'difabel'),
        (r'penyandang', 'penyandang disabilitas'),
        (r'berkebutuhan khusus', 'berkebutuhan khusus'),
        (r'special needs', 'special needs'),
        (r'disabled\s*(person|people|visitor|guest|toilet|parking|access|friendly)', 'disabled'),
        (r'disability\s*(toilet|access|friendly|parking|facility)', 'disability'),
        (r'(handicap|handicapped)', 'handicapped'),
    ],

    'lansia': [
        (r'\blansia\b', 'lansia'),
        (r'lanjut usia', 'lansia'),
        (r'\bmanula\b', 'lansia'),
        (r'\belderly\b', 'elderly'),
        (r'senior citizen', 'senior'),
        (r'orang tua.{0,15}(tidak kuat|susah|sulit|capek|lelah|jalan|bawa|ajak)', 'orang tua'),
        (r'(tidak kuat|susah|sulit|capek|lelah).{0,15}orang tua', 'orang tua'),
        (r'(bawa|ajak|untuk).{0,10}orang tua', 'orang tua'),
        (r'kakek|nenek', 'kakek nenek'),
        (r'grandpa|grandma|grandfather|grandmother', 'grandparent'),
    ],


    'akses_fisik': [
        # Elevator/lift
        (r'(naik|turun|pakai|gunakan|ada|tidak ada|rusak)\s*lift', 'lift'),
        (r'lift\s*(untuk|bagi|nya|khusus|penumpang|rusak|mati)', 'lift'),
        (r'\belevator\b', 'elevator'),
        # Escalator
        (r'\beskalator\b', 'eskalator'),
        (r'\bescalator\b', 'escalator'),
        # Stairs
        (r'(naik|turun|lewat|via|banyak|harus)\s*tangga', 'tangga'),
        (r'tangga.{0,15}(banyak|tinggi|curam|susah|sulit|capek|lelah|panjang)', 'tangga'),
        (r'(many|steep|long)\s*stairs', 'stairs'),
        (r'climb.{0,10}stairs', 'stairs'),
        # Ramp
        (r'\bramp\b', 'ramp'),
        (r'tanjakan', 'tanjakan'),
        # Special access
        (r'jalur\s*(khusus|disabilitas|difabel|prioritas|lansia|wheelchair)', 'jalur khusus'),
        (r'pintu\s*(khusus|disabilitas|difabel|samping)', 'pintu khusus'),
        (r'akses\s*(khusus|disabilitas|difabel|mudah|sulit)', 'akses'),
        (r'(priority|vip)\s*(lane|entrance|access|jalur|pintu)', 'priority access'),
        # Surface & terrain
        (r'(permukaan|lantai|surface).{0,15}(rata|smooth|flat|even)', 'permukaan rata'),
        (r'(permukaan|lantai|surface).{0,15}(tidak rata|uneven|rough|bumpy|berlubang)', 'permukaan tidak rata'),
        (r'(jalan|path|walkway).{0,15}(mulus|kasar|rusak|berbatu)', 'kondisi jalan'),
        (r'(licin|slippery|basah|wet)', 'licin'),
        (r'(paving|ubin|tiles|aspal|pavement)', 'jenis permukaan'),
        # Width & space
        (r'(lebar|width|wide|spacious).{0,15}(pintu|door|entrance|masuk)', 'lebar pintu'),
        (r'(sempit|narrow|tight).{0,15}(pintu|door|lorong|corridor|path|jalan)', 'sempit'),
        (r'(luas|spacious|wide).{0,15}(ruang|space|area)', 'ruang luas'),
        (r'(sesak|cramped|crowded|penuh)', 'sesak'),
        # Threshold & barriers
        (r'(threshold|ambang).{0,10}(pintu|door)', 'ambang pintu'),
        (r'(step|tangga).{0,10}(kecil|small)', 'step kecil'),
        (r'(halangan|hambatan|obstacle|barrier)', 'halangan'),
        (r'(celah|gap|jarak)', 'celah'),
        # Slope & incline
        (r'(kemiringan|slope|incline|gradient)', 'kemiringan'),
        (r'(tanjakan|uphill).{0,15}(curam|steep|terjal)', 'tanjakan curam'),
        (r'(turunan|downhill).{0,15}(curam|steep)', 'turunan curam'),
        (r'ramp.{0,15}(curam|landai|steep|gentle|smooth)', 'kondisi ramp'),
        # Automatic features
        (r'pintu\s*(otomatis|automatic|sensor)', 'pintu otomatis'),
        (r'automatic\s*door', 'automatic door'),
        (r'(push|tekan)\s*button.{0,10}(door|pintu)', 'tombol pintu'),
        # Ground level access
        (r'(ground|lantai\s*dasar)\s*(level|access|akses)', 'lantai dasar'),
        (r'(akses|masuk).{0,10}(langsung|direct)', 'akses langsung'),
        (r'(tidak perlu|no need).{0,15}(tangga|stairs)', 'tidak perlu tangga'),
    ],

    'jarak_jalan': [
        # Indonesian
        (r'jalan\s*kaki.{0,20}(jauh|capek|cape|lelah|panjang|lama|melelahkan)', 'jarak jalan'),
        (r'berjalan.{0,15}(jauh|capek|cape|lelah|lama|panjang|banyak)', 'jarak jalan'),
        (r'(jauh|capek|lelah|panjang|lama).{0,15}(berjalan|jalan kaki)', 'jarak jalan'),
        (r'(harus|banyak).{0,10}(jalan|berjalan)', 'banyak jalan'),
        (r'(capek|lelah|cape).{0,15}(jalan|kaki|berjalan)', 'capek jalan'),
        # Parking distance
        (r'parkir.{0,15}(jauh|dekat)', 'jarak parkir'),
        (r'dari parkir.{0,15}(jauh|dekat|jalan)', 'jarak parkir'),
        (r'parking.{0,15}(far|near|close|distant)', 'parking distance'),
        # English
        (r'(long|far|lots of)\s*walk', 'long walk'),
        (r'walk.{0,10}(far|long|tiring|exhausting|lot|much)', 'long walk'),
        (r'(tired|exhausted).{0,15}walk', 'tired walking'),
        (r'walking distance', 'walking distance'),
        # Distance from facilities
        (r'(jarak|distance).{0,15}(toilet|restroom|wc)', 'jarak toilet'),
        (r'(jarak|distance).{0,15}(lift|elevator)', 'jarak lift'),
        (r'(dekat|close|near).{0,15}(semua|everything|all)', 'semua dekat'),
        (r'(compact|padat|efisien).{0,10}(layout|tata letak)', 'layout efisien'),
        # Outdoor distances
        (r'(outdoor|luar ruangan).{0,15}(jalan|walk|jarak)', 'jalan outdoor'),
        (r'(terik|under sun|panas).{0,15}(jalan|walk)', 'jalan terik'),
        (r'(sheltered|berteduh).{0,10}(walkway|path|jalan)', 'jalan berteduh'),
    ],


    'fasilitas': [
        # Toilets
        (r'toilet\s*(khusus|disabilitas|difabel|disabled|lansia|wheelchair)', 'toilet khusus'),
        (r'(khusus|disabilitas|difabel|disabled|accessible)\s*toilet', 'toilet khusus'),
        (r'(nursing|baby)\s*room', 'nursing room'),
        (r'ruang\s*(menyusui|laktasi|bayi)', 'ruang menyusui'),
        (r'toilet\s*(luas|spacious|besar|wide)', 'toilet luas'),
        (r'toilet.{0,15}(sempit|narrow|kecil)', 'toilet sempit'),
        (r'(grab\s*bar|handrail|pegangan)', 'pegangan toilet'),
        (r'emergency\s*(button|call|bell)', 'tombol darurat'),
        # Parking
        (r'parkir\s*(khusus|disabilitas|difabel|disabled)', 'parkir khusus'),
        (r'(disabled|handicap|wheelchair)\s*parking', 'disabled parking'),
        (r'(parkir|parking).{0,15}(dekat|near|close).{0,15}(entrance|pintu masuk)', 'parkir dekat pintu'),
        (r'drop\s*off\s*(point|area|zone)', 'drop off point'),
        (r'(antar|drop).{0,10}(langsung|direct)', 'antar langsung'),
        (r'loading\s*zone', 'loading zone'),
        # Resting areas
        (r'(tempat|area|ruang)\s*(duduk|istirahat|rest)', 'tempat istirahat'),
        (r'(resting|sitting)\s*area', 'resting area'),
        (r'(kurang|tidak ada|sedikit).{0,10}(tempat duduk|bangku|kursi)', 'kurang tempat duduk'),
        (r'(bench|bangku).{0,15}(wheelchair|kursi roda)', 'bangku wheelchair'),
        (r'(wheelchair|kursi roda).{0,10}(parking|space|ruang)', 'ruang wheelchair'),
        (r'tempat\s*(tunggu|waiting).{0,15}(nyaman|comfortable)', 'tempat tunggu'),
        # Shade/shelter
        (r'(tempat|area)\s*(teduh|berteduh)', 'tempat teduh'),
        (r'(tidak ada|kurang).{0,10}(teduh|shade|atap)', 'tidak ada teduh'),
        (r'(shade|shelter|covered).{0,10}area', 'shaded area'),
        # Signage & navigation
        (r'(rambu|signage|petunjuk|tanda).{0,15}(wheelchair|disabilitas|jelas)', 'rambu jelas'),
        (r'(tactile|braille|paving)', 'tactile paving'),
        (r'guiding\s*(block|path)', 'guiding block'),
        # Support facilities
        (r'(charging|colokan|listrik).{0,10}(wheelchair|kursi roda)', 'charging wheelchair'),
        (r'wheelchair\s*(rental|sewa)', 'sewa wheelchair'),
        (r'(sewa|rental|pinjam).{0,10}(wheelchair|kursi roda|stroller)', 'rental'),
        (r'(locker|loker|penyimpanan).{0,15}(accessible|wheelchair)', 'locker accessible'),
    ],

    'aksesibilitas': [
        # Ramah/friendly
        (r'ramah\s*(disabilitas|difabel|lansia|anak|keluarga|wheelchair)', 'ramah'),
        (r'(tidak|kurang|belum)\s*ramah\s*(disabilitas|difabel|lansia)', 'tidak ramah'),
        (r'(wheelchair|disabled|elderly|family)\s*friendly', 'friendly'),
        (r'(not|less|un)\s*friendly.{0,15}(disabled|wheelchair|elderly)', 'not friendly'),
        (r'kid.{0,3}friendly', 'kid friendly'),
        # Accessible
        (r'wheelchair\s*(accessible|access)', 'wheelchair accessible'),
        (r'(accessible|access).{0,10}(wheelchair|disabled|elderly)', 'accessible'),
        (r'(mudah|easy).{0,10}(diakses|access)', 'mudah diakses'),
        (r'(sulit|susah|difficult).{0,10}(diakses|access)', 'sulit diakses'),
        # Recommended/suitable
        (r'(tidak|jangan|kurang)\s*(disarankan|recommended|cocok).{0,25}(lansia|elderly|disabilitas|difabel|hamil|pregnant|anak|bayi|jantung)', 'tidak disarankan'),
        (r'(not|dont|wouldn\'t)\s*recommend.{0,25}(elderly|disabled|wheelchair|pregnant|kids|children|heart)', 'not recommended'),
        (r'(cocok|suitable|bagus|recommended).{0,15}(keluarga|family|anak|kids|semua umur|all ages)', 'cocok keluarga'),
        (r'(cocok|suitable).{0,15}(lansia|elderly|disabled|disabilitas)', 'cocok lansia'),
        # Accessibility certification/standards
        (r'wheelchair\s*(certified|standard|compliant)', 'wheelchair certified'),
        (r'(universal|inclusive)\s*design', 'universal design'),
        (r'(ADA|accessibility)\s*compliant', 'ADA compliant'),
        (r'barrier\s*free', 'barrier free'),
        (r'(tanpa|bebas)\s*hambatan', 'bebas hambatan'),
        # Ease of access
        (r'(full|fully|completely)\s*accessible', 'fully accessible'),
        (r'(partially|sebagian)\s*accessible', 'partially accessible'),
        (r'(limited|terbatas)\s*access', 'limited access'),
        (r'(difficult|sulit|susah).{0,15}(wheelchair|kursi roda)', 'sulit wheelchair'),
        (r'(impossible|tidak mungkin).{0,15}(wheelchair|kursi roda)', 'tidak mungkin wheelchair'),
        # Independence
        (r'(independent|mandiri|sendiri).{0,15}(access|akses)', 'akses mandiri'),
        (r'(need|perlu|butuh).{0,10}(help|assistance|bantuan)', 'perlu bantuan'),
        (r'(tidak bisa|cannot|can\'t).{0,15}(sendiri|alone|independent)', 'tidak bisa sendiri'),
    ],

    'kondisi_fisik': [
        # Medical conditions
        (r'(penyakit|sakit)\s*jantung', 'sakit jantung'),
        (r'(heart|cardiac)\s*(condition|problem|disease)', 'heart condition'),
        (r'(lemah|weak)\s*jantung', 'lemah jantung'),
        (r'(darah tinggi|hipertensi|hypertension)', 'darah tinggi'),
        (r'(phobia|takut)\s*(ketinggian|height)', 'phobia ketinggian'),
        # Physical difficulty
        (r'(capek|lelah|cape|tired|exhausted).{0,15}(sekali|banget|very|so)', 'sangat lelah'),
        (r'(pusing|dizzy|mual|nausea)', 'pusing mual'),
        # Comfort issues
        (r'(panas|hot|terik).{0,15}(sekali|banget|very|extremely)', 'sangat panas'),
        (r'(tidak|kurang)\s*(nyaman|comfortable)', 'tidak nyaman'),
        # Wheelchair user specific
        (r'(transfer|pindah).{0,10}(wheelchair|kursi roda)', 'transfer wheelchair'),
        (r'(susah|difficult).{0,10}(manuver|maneuver|belok)', 'susah manuver'),
        (r'(tight|sempit).{0,10}(turn|belokan)', 'belokan sempit'),
        (r'(застряла|застрял|застряли|застрянуть)', 'застрял'),
        (r'(застряла|macet|застрял).{0,10}(wheelchair|kursi roda)', 'застряла wheelchair'),
    ],

    'bantuan': [
        (r'petugas.{0,15}(ramah|helpful|membantu|bantu|baik)', 'petugas ramah'),
        (r'staff.{0,15}(ramah|helpful|friendly|assist)', 'staff helpful'),
        (r'(ada|tersedia).{0,10}(bantuan|assistance|help)', 'ada bantuan'),
        (r'(tidak ada|kurang).{0,10}(bantuan|assistance|help|petugas)', 'kurang bantuan'),
        # Staff training & awareness
        (r'(staff|petugas).{0,15}(trained|terlatih|paham)', 'staff terlatih'),
        (r'(staff|petugas).{0,15}(not|kurang|tidak).{0,10}(helpful|aware|paham)', 'staff kurang paham'),
        (r'(assistance|bantuan).{0,10}(available|tersedia|ada)', 'bantuan tersedia'),
        (r'(call|panggil).{0,10}(assistance|bantuan|staff)', 'call assistance'),
        (r'(accompany|menemani|antar)', 'staff menemani'),
        # Physical assistance
        (r'(help|bantu).{0,10}(push|dorong|wheelchair)', 'bantu dorong'),
        (r'(carry|angkat|bawa).{0,10}(wheelchair|kursi roda)', 'angkat wheelchair'),
        (r'(porter|helper|pembantu)', 'porter'),
    ],


    'keamanan': [
        (r'(safety|keamanan).{0,15}(wheelchair|kursi roda)', 'keamanan wheelchair'),
        (r'(slippery|licin).{0,10}(danger|berbahaya)', 'bahaya licin'),
        (r'(edge|tepi|pinggir).{0,10}(protection|pengaman)', 'pengaman tepi'),
        (r'(emergency|darurat).{0,10}(exit|keluar)', 'pintu darurat'),
        (r'(evacuation|evakuasi).{0,10}(plan|route|jalur)', 'jalur evakuasi'),
    ],
}

import re

def get_sentence(text, start, end):
    """Extract sentence containing the match"""
    sent_start = start
    sent_end = end

    # Look backwards for sentence start
    for i in range(start, max(0, start-200), -1):
        if text[i] in '.!?\n':
            sent_start = i + 1
            break
        if i == max(0, start-200):
            sent_start = i

    # Look forwards for sentence end
    for i in range(end, min(len(text), end+200)):
        if text[i] in '.!?\n':
            sent_end = i + 1
            break
        if i == min(len(text), end+200) - 1:
            sent_end = i + 1

    return text[sent_start:sent_end].strip()


def extract_aspects(text, aspect_keywords):
    """Extract accessibility aspects from text"""
    if not text or len(text) < 20:
        return []

    text_lower = text.lower()
    results = []

    for aspect_type, patterns in aspect_keywords.items():
        for pattern, aspect_term in patterns:
            try:
                for m in re.finditer(pattern, text_lower):
                    sentence = get_sentence(text, m.start(), m.end())

                    if len(sentence) > 15:
                        results.append({
                            'aspect_type': aspect_type,
                            'aspect_term': aspect_term,
                            'sentence': sentence,
                            'matched': m.group(),
                        })
            except Exception as e:
                continue

    # Remove duplicates (same sentence + aspect)
    seen = set()
    unique = []
    for r in results:
        key = (r['sentence'], r['aspect_term'])
        if key not in seen:
            seen.add(key)
            unique.append(r)

    return unique

# Extract aspect mentions from your data
from collections import defaultdict
import json

extracted_data = []

print("Extracting aspects from reviews...")
for idx, row in df.iterrows():
    text = row['review_text']
    if pd.isna(text):
        continue

    aspects = extract_aspects(text, aspect_keywords)
    for aspect in aspects:
        extracted_data.append({
            'review_id': row['review_id'],
            'place_name': row['place_name'],
            'aspect_term': aspect['aspect_term'],
            'sentence': aspect['sentence'],
            'sentiment': None  # TO BE LABELED
        })

    # Progress update every 1000 reviews
    if idx % 1000 == 0:
        print(f"Processed {idx}/{len(df)} reviews, found {len(extracted_data)} aspects so far")

df_to_label = pd.DataFrame(extracted_data)

print(f"\nTotal: Found {len(df_to_label)} aspect mentions from {len(df)} reviews")
print(f"Aspects per review: {len(df_to_label)/len(df):.2f}")

# Sample
print("\nSample extracted aspects:")
display(df_to_label.head(10))

# Count aspects by type
print("\nAspects by category:")
aspect_counts = df_to_label['aspect_term'].value_counts().head(20)
display(aspect_counts)

df_to_label.to_csv('aspects_to_label.csv', index=False)
print(f"\nSaved to 'aspects_to_label.csv'")

!pip install transformers torch

import torch
from transformers import pipeline
from tqdm import tqdm
import pandas as pd

# Load sentiment model
sentiment_pipeline = pipeline(
    "sentiment-analysis",
    model="cardiffnlp/twitter-xlm-roberta-base-sentiment",
    device=0 if torch.cuda.is_available() else -1
)

df_to_label = pd.read_csv('aspects_to_label.csv')

print(f"Labeling {len(df_to_label)} aspects...")

labeled_sentiments = []

for idx, row in tqdm(df_to_label.iterrows(), total=len(df_to_label)):
    # Create context-aware input
    text = f"{row['aspect_term']}: {row['sentence']}"

    try:
        # Get sentiment
        result = sentiment_pipeline(text[:512])[0]

        # Map to labels
        label = result['label']
        if label in ['positive', 'Positive', 'LABEL_2']:
            sentiment = 'Positive'
        elif label in ['negative', 'Negative', 'LABEL_0']:
            sentiment = 'Negative'
        else:  # neutral, LABEL_1
            sentiment = 'Neutral'

        labeled_sentiments.append(sentiment)

    except Exception as e:
        print(f"\nError at {idx}: {e}")
        labeled_sentiments.append('Neutral')

# Add sentiments
df_to_label['sentiment'] = labeled_sentiments

# Save
df_to_label.to_csv('labeled_aspects.csv', index=False)

print("\n Labeling complete")
print("\nSentiment distribution:")
print(df_to_label['sentiment'].value_counts())

display(df_to_label.sample(10))

import matplotlib.pyplot as plt

# Prepare data
sentiment_counts = df_to_label['sentiment'].value_counts()

# Consistent order
order = ['Positive', 'Neutral', 'Negative']
sentiment_counts = sentiment_counts.reindex(order)

colors_pie = {
    'Positive': '#0088DE',   # soft blue
    'Neutral':  '#BEBEBE',   # soft gray
    'Negative': '#CC3333'    # soft red
}
colors_list = [colors_pie[s] for s in sentiment_counts.index]

# Plot
fig, ax = plt.subplots(figsize=(9, 7))

wedges, texts, autotexts = ax.pie(
    sentiment_counts.values,
    labels=sentiment_counts.index,
    colors=colors_list,
    autopct=lambda p: f'{p:.1f}%\n({int(p*sentiment_counts.sum()/100)})',
    startangle=90,
    counterclock=False,
    wedgeprops={'edgecolor': 'white', 'linewidth': 1.5},
    textprops={'fontsize': 12, 'fontweight': 'bold'}
)

# Improve text readability
for autotext in autotexts:
    autotext.set_color('white')
    autotext.set_fontsize(11)

# Title
ax.set_title(
    'Overall Sentiment Distribution\n'
    'for Wheelchair Accessibility Aspects',
    fontsize=15,
    fontweight='bold',
    pad=20
)

ax.axis('equal')

plt.tight_layout()
plt.savefig(
    '/content/drive/MyDrive/thesis/overall_sentiment_pie.png',
    dpi=300,
    bbox_inches='tight'
)

plt.show()
print("Chart saved: overall_sentiment_pie.png")

data = pd.read_csv('labeled_aspects.csv')

unique_sentiments = data['sentiment'].unique()
LABEL2ID = {sentiment: i for i, sentiment in enumerate(unique_sentiments)}
ID2LABEL = {i: sentiment for i, sentiment in enumerate(unique_sentiments)}

texts = []
labels = []

for _, row in data.iterrows():
    text = f"[ASP] {row['aspect_term']} [/ASP] {row['sentence']}"
    texts.append(text)
    labels.append(LABEL2ID[row['sentiment']])

# Check for "tersedia" pattern
print("Sentences with 'tersedia':")
tersedia_pos = data[(data['sentence'].str.contains('tersedia', case=False, na=False)) &
                     (data['sentiment'] == 'Positive')]
print(f"Positive: {len(tersedia_pos)}")

tersedia_neg = data[(data['sentence'].str.contains('tidak.*tersedia|tidak ada', case=False, na=False, regex=True)) &
                     (data['sentiment'] == 'Negative')]
print(f"Negative: {len(tersedia_neg)}")

# Check for "available" pattern
print("\nSentences with 'available':")
avail_pos = data[(data['sentence'].str.contains('available', case=False, na=False)) &
                 (data['sentiment'] == 'Positive')]
print(f"Positive: {len(avail_pos)}")

avail_neg = data[(data['sentence'].str.contains('not.*available|no.*available', case=False, na=False, regex=True)) &
                 (data['sentiment'] == 'Negative')]
print(f"Negative: {len(avail_neg)}")

# Create new examples matching the structure
new_examples = pd.DataFrame([
    # Positive - Indonesian availability
    {'review_id': 'AUG001', 'place_name': 'Training', 'aspect_term': 'kursi roda',
     'sentence': 'Tersedia kursi roda untuk pengunjung', 'sentiment': 'Positive'},
    {'review_id': 'AUG002', 'place_name': 'Training', 'aspect_term': 'kursi roda',
     'sentence': 'Ada kursi roda di tempat ini', 'sentiment': 'Positive'},
    {'review_id': 'AUG003', 'place_name': 'Training', 'aspect_term': 'kursi roda',
     'sentence': 'Menyediakan kursi roda gratis', 'sentiment': 'Positive'},
    {'review_id': 'AUG004', 'place_name': 'Training', 'aspect_term': 'akses kursi roda',
     'sentence': 'Kursi roda tersedia di lobi', 'sentiment': 'Positive'},
    {'review_id': 'AUG005', 'place_name': 'Training', 'aspect_term': 'kursi roda',
     'sentence': 'Tempat ini menyediakan akses kursi roda', 'sentiment': 'Positive'},

    # Positive - English availability
    {'review_id': 'AUG006', 'place_name': 'Training', 'aspect_term': 'wheelchair',
     'sentence': 'Wheelchair access is available here', 'sentiment': 'Positive'},
    {'review_id': 'AUG007', 'place_name': 'Training', 'aspect_term': 'wheelchair',
     'sentence': 'Wheelchairs are available for visitors', 'sentiment': 'Positive'},
    {'review_id': 'AUG008', 'place_name': 'Training', 'aspect_term': 'wheelchair access',
     'sentence': 'This place provides wheelchair access', 'sentiment': 'Positive'},
    {'review_id': 'AUG009', 'place_name': 'Training', 'aspect_term': 'wheelchair',
     'sentence': 'Wheelchair accessible facility', 'sentiment': 'Positive'},
    {'review_id': 'AUG010', 'place_name': 'Training', 'aspect_term': 'wheelchair',
     'sentence': 'They have wheelchairs available', 'sentiment': 'Positive'},

    # Negative - Indonesian no access
    {'review_id': 'AUG011', 'place_name': 'Training', 'aspect_term': 'kursi roda',
     'sentence': 'Tidak ada kursi roda di sini', 'sentiment': 'Negative'},
    {'review_id': 'AUG012', 'place_name': 'Training', 'aspect_term': 'kursi roda',
     'sentence': 'Kursi roda tidak tersedia', 'sentiment': 'Negative'},
    {'review_id': 'AUG013', 'place_name': 'Training', 'aspect_term': 'akses kursi roda',
     'sentence': 'Tidak tersedia akses kursi roda', 'sentiment': 'Negative'},
    {'review_id': 'AUG014', 'place_name': 'Training', 'aspect_term': 'kursi roda',
     'sentence': 'Tidak ada akses untuk kursi roda', 'sentiment': 'Negative'},
    {'review_id': 'AUG015', 'place_name': 'Training', 'aspect_term': 'kursi roda',
     'sentence': 'Kursi roda tidak disediakan', 'sentiment': 'Negative'},

    # Negative - English no access
    {'review_id': 'AUG016', 'place_name': 'Training', 'aspect_term': 'wheelchair',
     'sentence': 'No wheelchair access available', 'sentiment': 'Negative'},
    {'review_id': 'AUG017', 'place_name': 'Training', 'aspect_term': 'wheelchair access',
     'sentence': 'Wheelchair access not available', 'sentiment': 'Negative'},
    {'review_id': 'AUG018', 'place_name': 'Training', 'aspect_term': 'wheelchair',
     'sentence': 'No wheelchairs provided here', 'sentiment': 'Negative'},
    {'review_id': 'AUG019', 'place_name': 'Training', 'aspect_term': 'wheelchair access',
     'sentence': 'This place has no wheelchair access', 'sentiment': 'Negative'},
    {'review_id': 'AUG020', 'place_name': 'Training', 'aspect_term': 'wheelchair',
     'sentence': 'Wheelchairs are not available', 'sentiment': 'Negative'},

    # Neutral - just mentions (usage statements)
    {'review_id': 'AUG021', 'place_name': 'Training', 'aspect_term': 'kursi roda',
     'sentence': 'Saya menggunakan kursi roda', 'sentiment': 'Neutral'},
    {'review_id': 'AUG022', 'place_name': 'Training', 'aspect_term': 'kursi roda',
     'sentence': 'Dia datang dengan kursi roda', 'sentiment': 'Neutral'},
    {'review_id': 'AUG023', 'place_name': 'Training', 'aspect_term': 'wheelchair',
     'sentence': 'I use a wheelchair', 'sentiment': 'Neutral'},
    {'review_id': 'AUG024', 'place_name': 'Training', 'aspect_term': 'wheelchair',
     'sentence': 'My friend brought a wheelchair', 'sentiment': 'Neutral'},
    {'review_id': 'AUG025', 'place_name': 'Training', 'aspect_term': 'kursi roda',
     'sentence': 'Kursi roda saya berwarna hitam', 'sentiment': 'Neutral'},
])

# Combine with original data
augmented_data = pd.concat([data, new_examples], ignore_index=True)

# Verify the structure
print("Original data shape:", data.shape)
print("New examples shape:", new_examples.shape)
print("Augmented data shape:", augmented_data.shape)
print("\nColumn check:")
print(augmented_data.columns.tolist())
print("\nFirst few augmented rows:")
print(augmented_data.tail(5))

# Save augmented dataset
augmented_data.to_csv('labeled_aspects_augmented.csv', index=False)

print(f"\n Saved augmented data")
print(f"Original: {len(data)} rows")
print(f"Added: {len(new_examples)} rows")
print(f"Total: {len(augmented_data)} rows")

data = pd.read_csv('labeled_aspects_augmented.csv')

unique_sentiments = data['sentiment'].unique()
LABEL2ID = {sentiment: i for i, sentiment in enumerate(unique_sentiments)}
ID2LABEL = {i: sentiment for i, sentiment in enumerate(unique_sentiments)}

texts = []
labels = []

for _, row in data.iterrows():
    text = f"[ASP] {row['aspect_term']} [/ASP] {row['sentence']}"
    texts.append(text)
    labels.append(LABEL2ID[row['sentiment']])

from sklearn.model_selection import train_test_split
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from transformers import TrainingArguments, Trainer, EarlyStoppingCallback, pipeline
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

# Split: 80% train, 10% val, 10% test
train_texts, temp_texts, train_labels, temp_labels = train_test_split(
    texts, labels, test_size=0.2, stratify=labels, random_state=42
)

val_texts, test_texts, val_labels, test_labels = train_test_split(
    temp_texts, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42
)

print(f"Train: {len(train_texts)}")
print(f"Val: {len(val_texts)}")
print(f"Test: {len(test_texts)}")

MODEL_NAME = "xlm-roberta-base"

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

# Add special tokens for aspect marking
special_tokens = {"additional_special_tokens": ["[ASP]", "[/ASP]"]}
tokenizer.add_special_tokens(special_tokens)

print(f"Tokenizer loaded: {MODEL_NAME}")
print(f"Vocab size: {len(tokenizer)}")

# Load model
model = AutoModelForSequenceClassification.from_pretrained(
    MODEL_NAME,
    num_labels=3,
    id2label=ID2LABEL,
    label2id=LABEL2ID,
)

# Resize embeddings for new special tokens
model.resize_token_embeddings(len(tokenizer))

print(f"Parameters: {model.num_parameters():,}")

!pip install datasets
from datasets import Dataset

MAX_LENGTH = 128

def tokenize_function(examples):
    return tokenizer(
        examples["text"],
        padding="max_length",
        truncation=True,
        max_length=MAX_LENGTH,
    )

# Create datasets
train_dataset = Dataset.from_dict({"text": train_texts, "label": train_labels})
val_dataset = Dataset.from_dict({"text": val_texts, "label": val_labels})
test_dataset = Dataset.from_dict({"text": test_texts, "label": test_labels})

# Tokenize
train_dataset = train_dataset.map(tokenize_function, batched=True)
val_dataset = val_dataset.map(tokenize_function, batched=True)
test_dataset = test_dataset.map(tokenize_function, batched=True)

# Set format
train_dataset.set_format("torch", columns=["input_ids", "attention_mask", "label"])
val_dataset.set_format("torch", columns=["input_ids", "attention_mask", "label"])
test_dataset.set_format("torch", columns=["input_ids", "attention_mask", "label"])

import os
import torch
import gc
from transformers import TrainingArguments, Trainer, EarlyStoppingCallback
import numpy as np
from sklearn.metrics import accuracy_score, classification_report

# Clear memory
torch.cuda.empty_cache()
gc.collect()

print(f"GPU Available: {torch.cuda.is_available()}")
gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'
print(f"GPU Name: {gpu_name}")

gpu_memory = 'N/A'
if torch.cuda.is_available():
    try:
        gpu_memory = f"{torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB"
    except AssertionError:
        # Fallback if get_device_properties still fails for some reason
        gpu_memory = 'CUDA available but properties unretrievable'
print(f"GPU Memory: {gpu_memory}")

def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    accuracy = (predictions == labels).mean()
    return {"accuracy": accuracy}

training_args = TrainingArguments(
    output_dir="./xlm-roberta-absa-accessibility",

    # Training hyperparameters
    num_train_epochs=5,
    per_device_train_batch_size=64,
    per_device_eval_batch_size=128,
    gradient_accumulation_steps=1,

    # Optimizer
    learning_rate=2e-5,
    weight_decay=0.01,
    warmup_ratio=0.1,
    max_grad_norm=1.0,

    # Evaluation & saving
    eval_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    greater_is_better=True,
    save_total_limit=2,

    # Logging
    logging_steps=10,
    logging_first_step=True,
    logging_dir='./logs',
    report_to="none",

    # Performance
    fp16=True,
    dataloader_num_workers=4,
    dataloader_pin_memory=True,

    # Reproducibility
    seed=42,
    data_seed=42,
)

if hasattr(model, 'gradient_checkpointing_enable'):
    model.gradient_checkpointing_enable()
    print("Gradient checkpointing enabled")

# Check if datasets are already tokenized
if "input_ids" not in train_dataset.column_names:
    print("❌ ERROR: Datasets not tokenized!")
    print("Run the tokenization cell first before training")
    raise ValueError("Datasets must be tokenized before training")

print(f"Train dataset: {len(train_dataset)} samples")
print(f"Val dataset: {len(val_dataset)} samples")
print(f"Test dataset: {len(test_dataset)} samples")

# Verify class balance
train_labels = [item['label'] for item in train_dataset]
print(f"\nClass distribution in training:")
for label_id, label_name in ID2LABEL.items():
    count = train_labels.count(label_id)
    print(f"  {label_name}: {count} ({count/len(train_labels)*100:.1f}%)")

print("CREATING TRAINER")

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],
)

try:
    train_result = trainer.train()
    print("Training Completed :D")
    print("="*60)
    print(f"Training loss: {train_result.training_loss:.4f}")
    print(f"Training time: {train_result.metrics['train_runtime']:.2f} seconds")
    print(f"Steps per second: {train_result.metrics['train_samples_per_second']:.2f}")

except Exception as e:
    print("Training Failed!")
    print("="*60)
    print(f"Error: {str(e)}")
    import traceback
    traceback.print_exc()
    raise

import pandas as pd
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
import re

print("Processing test predictions to create df_final...")

test_data = []

for idx in range(len(test_texts)):
    text = test_texts[idx]
    true_label_id = test_labels[idx]
    pred_label_id = test_preds[idx]
    conf = confidences[idx]

    # Parse text to extract aspect_term and sentence
    match = re.search(r'\[ASP\]\s*(.*?)\s*\[/ASP\]\s*(.*)', text)

    if match:
        aspect_term = match.group(1).strip()
        sentence = match.group(2).strip()

        test_data.append({
            'aspect_term': aspect_term,
            'sentence': sentence,
            'true_label_id': true_label_id,
            'pred_label_id': pred_label_id,
            'confidence': conf
        })

df_test = pd.DataFrame(test_data)

df_test_merged = df_test.merge(
    augmented_data[['aspect_term', 'sentence', 'review_id', 'place_name']].drop_duplicates(),
    on=['aspect_term', 'sentence'],
    how='left'
)

df_final = df_test_merged.merge(
    df[['review_id', 'rating', 'published_at_date']].drop_duplicates('review_id'), # drop_duplicates in case of multiple aspect mentions for one review
    on='review_id',
    how='left'
)

df_final['true_sentiment'] = df_final['true_label_id'].map(ID2LABEL)
df_final['predicted_sentiment'] = df_final['pred_label_id'].map(ID2LABEL)
df_final['is_correct'] = df_final['true_sentiment'] == df_final['predicted_sentiment']

df_final['aspect_type'] = df_final['aspect_term'].apply(get_aspect_type)
df_final['facilities_mentioned'] = df_final['sentence'].apply(extract_facilities)
df_final['confidence'] = df_final['confidence'].round(4)
df_final = df_final.rename(columns={'sentence': 'review_text'})

# Compute Confusion Matrix
cm = confusion_matrix(
    df_final['true_sentiment'],
    df_final['predicted_sentiment'],
    labels=['Positive', 'Neutral', 'Negative']
)
cm_df = pd.DataFrame(
    cm,
    index=['True_Positive', 'True_Neutral', 'True_Negative'],
    columns=['Pred_Positive', 'Pred_Neutral', 'Pred_Negative']
)

# Display the confusion matrix
print("Confusion Matrix:")
display(cm_df)

# Generate and display the classification report
print("\nClassification Report:")
report = classification_report(
    df_final['true_sentiment'],
    df_final['predicted_sentiment'],
    labels=['Positive', 'Neutral', 'Negative'],
    output_dict=True
)
df_report = pd.DataFrame(report).transpose()
display(df_report)

from sklearn.metrics import classification_report

# Display the confusion matrix again for easy reference
print("Confusion Matrix:")
display(cm_df)

# Generate and display the classification report
print("\n Classification Report:")
report = classification_report(
    df_final['true_sentiment'],
    df_final['predicted_sentiment'],
    labels=['Positive', 'Neutral', 'Negative'],
    output_dict=True
)
df_report = pd.DataFrame(report).transpose()
display(df_report)

import pandas as pd
import numpy as np
import torch
from scipy.special import softmax

# Predict
test_results = trainer.predict(test_dataset)

logits = test_results.predictions
probs = softmax(logits, axis=1)

test_preds = np.argmax(probs, axis=1)
confidences = np.max(probs, axis=1)

# Convert label id to label name
ID2LABEL = {v:k for k,v in LABEL2ID.items()}
pred_sentiments = [ID2LABEL[p] for p in test_preds]

import pandas as pd
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
import re
from scipy.special import softmax
import os

# Ensure necessary data and functions are available
if 'df' not in globals():
    print("Loading original dataframe...")
    import glob
    csv_file_path = "/content/drive/MyDrive/thesis/Deployment"
    data_files = glob.glob(f"{csv_file_path}/*.csv")
    dfs = []
    for f in data_files:
        temp_df = pd.read_csv(f)
        temp_df["source_file"] = os.path.basename(f)
        dfs.append(temp_df)
    df = pd.concat(dfs, ignore_index=True)
    df = df.dropna(subset=['review_text'])
    df['published_at_date'] = df['published_at_date'].str.split('T').str[0]
    df['published_at_date'] = pd.to_datetime(df['published_at_date'], format='%Y-%m-%d')
    print(f"Loaded {len(df)} reviews from original data")

if 'augmented_data' not in globals():
    print("Loading augmented data...")
    augmented_data = pd.read_csv('labeled_aspects_augmented.csv')
    print(f"Loaded {len(augmented_data)} augmented aspects")

# Define get_aspect_type and extract_facilities functions if not already defined
if 'get_aspect_type' not in globals():
    def get_aspect_type(aspect_term):
        for asp_type, patterns in aspect_keywords.items():
            for pattern, term in patterns:
                if term == aspect_term:
                    return asp_type
        return ''

if 'extract_facilities' not in globals():
    facility_keywords = {
        "ramp access": [r"ramp", r"ram"],
        "wheelchair": [r"kursi roda", r"wheelchair"],
        "lift": [r"lift", r"elevator"],
        "handrail": [r"handrail", r"pegangan"],
        "accessible toilet": [r"toilet disabilitas", r"toilet difabel", r"accessible toilet"],
        "wide door": [r"pintu lebar", r"wide door"],
        "parking": [r"parkir", r"parking"],
        "tactile path": [r"tactile", r"guiding block"]
    }
    def extract_facilities(text):
        text = text.lower()
        found = []
        for facility, patterns in facility_keywords.items():
            for p in patterns:
                if re.search(p, text):
                    found.append(facility)
                    break
        return "; ".join(sorted(set(found)))


# Perform predictions on the test dataset
print("\nRunning predictions on the test dataset...")

test_results = trainer.predict(test_dataset)

logits = test_results.predictions
probs = softmax(logits, axis=1)

test_preds = np.argmax(probs, axis=1)
confidences = np.max(probs, axis=1)

# Create DataFrame from test results
print("\nProcessing test predictions to create df_final...")

test_data = []

for idx in range(len(test_texts)):
    text = test_texts[idx]
    true_label_id = test_labels[idx]
    pred_label_id = test_preds[idx]
    conf = confidences[idx]

    # Parse text to extract aspect_term and sentence
    match = re.search(r'\[ASP\]\s*(.*?)\s*\[/ASP\]\s*(.*)', text)

    if match:
        aspect_term = match.group(1).strip()
        sentence = match.group(2).strip()

        test_data.append({
            'aspect_term': aspect_term,
            'sentence': sentence,
            'true_label_id': true_label_id,
            'pred_label_id': pred_label_id,
            'confidence': conf
        })

df_test = pd.DataFrame(test_data)
print(f"Created test DataFrame: {len(df_test)} rows")

# Merge with augmented data for review_id and place_name
print("\n Merging with augmented data...")
df_test_merged = df_test.merge(
    augmented_data[['aspect_term', 'sentence', 'review_id', 'place_name']].drop_duplicates(),
    on=['aspect_term', 'sentence'],
    how='left'
)
print(f" Merged: {len(df_test_merged)} rows")

# Merge with original df for rating and published_at_date
print("\n Merging with original data for ratings...")
df_final = df_test_merged.merge(
    df[['review_id', 'rating', 'published_at_date']].drop_duplicates('review_id'), # drop_duplicates in case of multiple aspect mentions for one review
    on='review_id',
    how='left'
)
print(f" Final merge: {len(df_final)} rows")

# Add additional columns and finalize df_final
print("\n Adding additional columns...")

df_final['true_sentiment'] = df_final['true_label_id'].map(ID2LABEL)
df_final['predicted_sentiment'] = df_final['pred_label_id'].map(ID2LABEL)
df_final['is_correct'] = df_final['true_sentiment'] == df_final['predicted_sentiment']

df_final['aspect_type'] = df_final['aspect_term'].apply(get_aspect_type)
df_final['facilities_mentioned'] = df_final['sentence'].apply(extract_facilities)
df_final['confidence'] = df_final['confidence'].round(4)
df_final = df_final.rename(columns={'sentence': 'review_text'})

# Compute and display Confusion Matrix and Classification Report
print("\n" + "="*80)
print("MODEL EVALUATION RESULTS")
print("="*80)

# Compute Confusion Matrix
cm = confusion_matrix(
    df_final['true_sentiment'],
    df_final['predicted_sentiment'],
    labels=['Positive', 'Neutral', 'Negative']
)
cm_df = pd.DataFrame(
    cm,
    index=['True_Positive', 'True_Neutral', 'True_Negative'],
    columns=['Pred_Positive', 'Pred_Neutral', 'Pred_Negative']
)

print("\nConfusion Matrix:")
display(cm_df)

# Generate and display the classification report
print("\nClassification Report:")
report = classification_report(
    df_final['true_sentiment'],
    df_final['predicted_sentiment'],
    labels=['Positive', 'Neutral', 'Negative'],
    output_dict=True
)
df_report = pd.DataFrame(report).transpose()
display(df_report)

print("\n Evaluation complete!")

MODEL_SAVE_PATH = "./xlm-roberta-absa-accessibility/final"
trainer.save_model(MODEL_SAVE_PATH)
tokenizer.save_pretrained(MODEL_SAVE_PATH)

import shutil
drive_save_path = "/content/drive/MyDrive/models/absa_wheelchair_model_v2"
if os.path.exists(drive_save_path):
    shutil.rmtree(drive_save_path)
shutil.copytree(MODEL_SAVE_PATH, drive_save_path)

print("Done! Model Saved!")

# Load model for inference
classifier = pipeline(
    "text-classification",
    model=MODEL_SAVE_PATH,
    tokenizer=MODEL_SAVE_PATH,
    device=0 if torch.cuda.is_available() else -1,
)

# Test cases
test_cases = [
    # Positive
    ("[ASP] ramp [/ASP] ramp cukup landai.", "Neutral"),
    ("[ASP] wheelchair [/ASP] Wheelchair access is available and easy to use.", "Positive"),
    ("[ASP] ramah disabilitas [/ASP] Tempat ini sangat ramah disabilitas.", "Positive"),

    # Negative
    ("[ASP] kursi roda [/ASP] Tidak ada akses untuk kursi roda.", "Negative"),
    ("[ASP] wheelchair [/ASP] No wheelchair access available.", "Negative"),
    ("[ASP] disabilitas [/ASP] Tempat ini tidak ramah disabilitas.", "Negative"),

    # Neutral
    ("[ASP] kursi roda [/ASP] Roda kursi roda saya rusak ketika mengunjungi tempat ini.", "Neutral"),
]

print("Test Predictions:")
print("=" * 70)

correct = 0
for text, expected in test_cases:
    result = classifier(text)[0]
    is_correct = result['label'] == expected
    correct += is_correct
    status = "Correct" if is_correct else "wrong"

    print(f"\n{status} \nInput: {text[:50]}...")
    print(f"  Predicted: {result['label']} ({result['score']:.1%})")
    print(f"  Expected: {expected}")

print(f"Accuracy: {correct}/{len(test_cases)} ({correct/len(test_cases):.0%})")

# Accessibility Flagging

def map_accessibility(score):
    if score < 0.4:
        return "Bad"
    elif score < 0.7:
        return "Neutral"
    else:
        return "Good"

# Facility Keyword Extraction

import re

facility_keywords = {
    "ramp access": [r"ramp", r"ram"],
    "wheelchair": [r"kursi roda", r"wheelchair"],
    "lift": [r"lift", r"elevator"],
    "handrail": [r"handrail", r"pegangan"],
    "accessible toilet": [r"toilet disabilitas", r"toilet difabel", r"accessible toilet"],
    "wide door": [r"pintu lebar", r"wide door"],
    "parking": [r"parkir", r"parking"],
    "tactile path": [r"tactile", r"guiding block"]
}

def extract_facilities(text):
    text = text.lower()
    found = []

    for facility, patterns in facility_keywords.items():
        for p in patterns:
            if re.search(p, text):
                found.append(facility)
                break

    return "; ".join(sorted(set(found)))

# Run Inference

import torch
import numpy as np

def predict_scores(texts, tokenizer, model, max_len=128, batch_size=16):
    model.eval()
    scores = []

    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]

        enc = tokenizer(
            batch,
            padding=True,
            truncation=True,
            max_length=max_len,
            return_tensors="pt"
        )

        with torch.no_grad():
            outputs = model(**enc)
            probs = torch.softmax(outputs.logits, dim=1)
            pos_scores = probs[:,1].cpu().numpy()

        scores.extend(pos_scores)

    return np.array(scores)

import torch
import numpy as np

def predict_scores(texts, tokenizer, model, max_len=128, batch_size=16):
    model.eval()
    scores = []

    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]

        enc = tokenizer(
            batch,
            padding=True,
            truncation=True,
            max_length=max_len,
            return_tensors="pt"
        )

        with torch.no_grad():
            outputs = model(**enc)
            probs = torch.softmax(outputs.logits, dim=1)
            pos_scores = probs[:,1].cpu().numpy()

        scores.extend(pos_scores)

    return np.array(scores)

# Predict entire dataset
print("Predicting on entire dataset for prototype...")

from transformers import pipeline
import torch

# Load model that already trained
classifier = pipeline(
    "text-classification",
    model=MODEL_SAVE_PATH,
    tokenizer=MODEL_SAVE_PATH,
    device=0 if torch.cuda.is_available() else -1,
)

# Load data (aspects augmented)
data_full = pd.read_csv('labeled_aspects_augmented.csv')

print(f"Total data untuk prediksi: {len(data_full)}")

# Predict
all_predictions = []

for idx, row in data_full.iterrows():
    # Format text
    text = f"[ASP] {row['aspect_term']} [/ASP] {row['sentence']}"

    # Predict
    result = classifier(text, truncation=True, max_length=128)[0]

    all_predictions.append({
        'place_name': row['place_name'],
        'review_id': row['review_id'],
        'aspect_term': row['aspect_term'],
        'sentence': row['sentence'],
        'predicted_sentiment': result['label'],
        'confidence': result['score']
    })

    if (idx + 1) % 100 == 0:
        print(f"Processed {idx + 1}/{len(data_full)} reviews...")

# Create dataframe
df_all_predictions = pd.DataFrame(all_predictions)

# Save
df_all_predictions.to_csv('/content/drive/MyDrive/thesis/all_predictions_for_prototype.csv', index=False)
print(f"\n Saved all predictions!")

# Formatting
prototype_ui_data = []

for place in df_all_predictions['place_name'].unique():
    place_data = df_all_predictions[df_all_predictions['place_name'] == place]

    total = len(place_data)
    positive = len(place_data[place_data['predicted_sentiment'] == 'Positive'])
    neutral = len(place_data[place_data['predicted_sentiment'] == 'Neutral'])
    negative = len(place_data[place_data['predicted_sentiment'] == 'Negative'])

    positive_pct = (positive / total * 100) if total > 0 else 0

    # Text summary
    if positive_pct >= 70:
        summary = f"{positive_pct:.0f}% pengunjung setuju bahwa {place} memiliki aksesibilitas kursi roda yang SANGAT BAIK"
    elif positive_pct >= 50:
        summary = f"{positive_pct:.0f}% pengunjung setuju bahwa {place} memiliki aksesibilitas kursi roda yang BAIK"
    elif positive_pct >= 30:
        summary = f"{positive_pct:.0f}% pengunjung setuju bahwa {place} memiliki aksesibilitas kursi roda yang CUKUP"
    else:
        summary = f"Hanya {positive_pct:.0f}% pengunjung yang menyatakan {place} memiliki aksesibilitas kursi roda yang baik"

    # Breakdown per aspect
    aspect_breakdown = {}
    for aspect in place_data['aspect_term'].unique():
        aspect_data = place_data[place_data['aspect_term'] == aspect]
        aspect_positive = len(aspect_data[aspect_data['predicted_sentiment'] == 'Positive'])
        aspect_total = len(aspect_data)
        aspect_breakdown[aspect] = {
            'positive': aspect_positive,
            'total': aspect_total,
            'percentage': (aspect_positive / aspect_total * 100) if aspect_total > 0 else 0
        }

    prototype_ui_data.append({
        'place_name': place,
        'summary_text': summary,
        'total_reviews': total,
        'positive_reviews': positive,
        'neutral_reviews': neutral,
        'negative_reviews': negative,
        'accessibility_score': round(positive_pct, 1),
        'aspect_details': aspect_breakdown
    })

# Save
import json
with open('/content/drive/MyDrive/thesis/prototype_ui_data.json', 'w') as f:
    json.dump(prototype_ui_data, f, indent=2)

print("For UI data saved as JSON!")

# Preview
print("\n Preview:")
for data in prototype_ui_data[:3]:
    print(f" {data['place_name']}")
    print(f" {data['summary_text']}")
    print(f"   Based on {data['total_reviews']} reviews analyzed")
    print(f"\n   Aspect Breakdown:")
    for aspect, details in list(data['aspect_details'].items())[:5]:
        print(f"   - {aspect}: {details['percentage']:.0f}% positive ({details['positive']}/{details['total']})")

# Inference

data_full = pd.read_csv('labeled_aspects_augmented.csv')

print(f"\n Dataset Overview:")
print(f"Total reviews: {len(data_full)}")
print(f"Unique places: {data_full['place_name'].nunique()}")

all_texts = []
all_metadata = []

for idx, row in data_full.iterrows():
    # text formatting
    text = f"[ASP] {row['aspect_term']} [/ASP] {row['sentence']}"
    all_texts.append(text)
    all_metadata.append({
        'place_name': row['place_name'],
        'review_id': row['review_id'],
        'aspect_term': row['aspect_term'],
        'sentence': row['sentence'],
    })

# Tokenize
print("\n Tokenizing entire dataset")
all_encodings = tokenizer(
    all_texts,
    padding=True,
    truncation=True,
    max_length=128,
    return_tensors="pt"
)

# Create dataset
from datasets import Dataset
full_dataset = Dataset.from_dict({
    'input_ids': all_encodings['input_ids'],
    'attention_mask': all_encodings['attention_mask']
})

# Predict
print("\n Running inference on entire dataset")
predictions = trainer.predict(full_dataset)

# Extract result
from scipy.special import softmax
logits = predictions.predictions
probs = softmax(logits, axis=1)
pred_labels = np.argmax(probs, axis=1)
confidences = np.max(probs, axis=1)

# Combine
print("\n Creating final dataset with ratings")

# mapping review_id to rating from df original
if 'df' not in globals():
    print("Loading original dataframe")
    import glob
    csv_file_path = "/content/drive/MyDrive/thesis/Deployment"
    data_files = glob.glob(f"{csv_file_path}/*.csv")

    dfs = []
    for f in data_files:
        temp_df = pd.read_csv(f)
        temp_df["source_file"] = os.path.basename(f)
        dfs.append(temp_df)

    df = pd.concat(dfs, ignore_index=True)
    df = df.dropna(subset=['review_text'])
    print(f"Loaded {len(df)} reviews from original data")

# quick dictionary
review_lookup = {}
for idx, row in df.iterrows():
    review_lookup[row['review_id']] = {
        'rating': row['rating'],
        'published_at_date': row['published_at_date']
    }

prototype_data = []

for idx, metadata in enumerate(all_metadata):
    pred_sentiment = ID2LABEL[pred_labels[idx]]

    # aspect type
    aspect_type = ''
    for asp_type, patterns in aspect_keywords.items():
        for pattern, term in patterns:
            if term == metadata['aspect_term']:
                aspect_type = asp_type
                break
        if aspect_type:
            break

    # Extract facilities
    facilities = extract_facilities(metadata['sentence'])

    # Get rating dan published_at_date dari review_id
    review_info = review_lookup.get(metadata['review_id'], {'rating': np.nan, 'published_at_date': pd.NaT})
    rating = review_info['rating']
    published_at = review_info['published_at_date']

    prototype_data.append({
        'review_id': metadata['review_id'],
        'place_name': metadata['place_name'],
        'published_at_date': published_at,
        'rating': rating,
        'sentence': metadata['sentence'],
        'aspect_term': metadata['aspect_term'],
        'aspect_type': aspect_type,
        'predicted_sentiment': pred_sentiment,
        'confidence': round(confidences[idx], 4),
        'facilities_mentioned': facilities
    })

df_prototype = pd.DataFrame(prototype_data)

# Convert 'rating' to numeric and 'published_at_date' to datetime, coercing errors
df_prototype['rating'] = pd.to_numeric(df_prototype['rating'], errors='coerce')
df_prototype['published_at_date'] = pd.to_datetime(df_prototype['published_at_date'], errors='coerce')

# Reorder columns untuk lebih readable
df_prototype = df_prototype[[
    'review_id',
    'place_name',
    'published_at_date',
    'rating',
    'sentence',
    'aspect_term',
    'aspect_type',
    'predicted_sentiment',
    'confidence',
    'facilities_mentioned'
]]

# Save
output_path = '/content/drive/MyDrive/thesis/prototype_full_predictions.csv'
df_prototype.to_csv(output_path, index=False)

print(f"\n Full predictions saved to: {output_path}")
print(f"\n Dataset Info:")
print(f"Total predictions: {len(df_prototype)}")
print(f"Columns: {df_prototype.columns.tolist()}")

print(f"\n Prediction Statistics:")
print(df_prototype['predicted_sentiment'].value_counts())
print(f"\nAverage confidence: {df_prototype['confidence'].mean():.2%}")

print(f"\n Rating Distribution:")
print(df_prototype['rating'].value_counts().sort_index())

# Show sample
print(f"\n Sample Data:")
display(df_prototype.head(10))

# Download
from google.colab import files
files.download(output_path)

# Merge

import pandas as pd
import numpy as np
import re

# Load data augmented
data_augmented = pd.read_csv('labeled_aspects_augmented.csv')

test_data = []

for idx in range(len(test_texts)):
    text = test_texts[idx]
    true_label_id = test_labels[idx]
    pred_label_id = test_preds[idx]
    conf = confidences[idx]

    # Parse text
    match = re.search(r'\[ASP\]\s*(.*?)\s*\[/ASP\]\s*(.*)', text)

    if match:
        aspect_term = match.group(1).strip()
        sentence = match.group(2).strip()

        test_data.append({
            'aspect_term': aspect_term,
            'sentence': sentence,
            'true_label_id': true_label_id,
            'pred_label_id': pred_label_id,
            'confidence': conf
        })

    if (idx + 1) % 100 == 0:
        print(f"  Processed {idx + 1}/{len(test_texts)} samples")

df_test = pd.DataFrame(test_data)

print(f" Created test DataFrame: {len(df_test)} rows")

# Merge with augmented data
print("\n Merging with augmented data")

df_test_merged = df_test.merge(
    data_augmented[['aspect_term', 'sentence', 'review_id', 'place_name']],
    on=['aspect_term', 'sentence'],
    how='left'
)

print(f" Merged: {len(df_test_merged)} rows")

# STEP 3: Merge dengan df original untuk mendapatkan rating
print("\n Merging with original data for ratings")

df_final = df_test_merged.merge(
    df[['review_id', 'rating', 'published_at_date']],
    on='review_id',
    how='left'
)

print(f" Final merge: {len(df_final)} rows")

# STEP 4: Tambahkan kolom lainnya
print("\n Adding additional columns")

# Konversi label IDs ke sentiment names
df_final['true_sentiment'] = df_final['true_label_id'].map(ID2LABEL)
df_final['predicted_sentiment'] = df_final['pred_label_id'].map(ID2LABEL)
df_final['is_correct'] = df_final['true_sentiment'] == df_final['predicted_sentiment']

# Aspect type
def get_aspect_type(aspect_term):
    for asp_type, patterns in aspect_keywords.items():
        for pattern, term in patterns:
            if term == aspect_term:
                return asp_type
    return ''

df_final['aspect_type'] = df_final['aspect_term'].apply(get_aspect_type)

# Facilities
df_final['facilities_mentioned'] = df_final['sentence'].apply(extract_facilities)

# Round confidence
df_final['confidence'] = df_final['confidence'].round(4)

# Reorder columns
df_final = df_final[[
    'review_id',
    'place_name',
    'published_at_date',
    'rating',
    'sentence',
    'aspect_term',
    'aspect_type',
    'true_sentiment',
    'predicted_sentiment',
    'confidence',
    'facilities_mentioned',
    'is_correct'
]]

# Rename sentence to review_text for consistency
df_final = df_final.rename(columns={'sentence': 'review_text'})

# Save
output_path = '/content/drive/MyDrive/thesis/test_results_complete.csv'
df_final.to_csv(output_path, index=False)

print(f"\n Saved to: {output_path}")

# Statistics
print("TEST RESULTS SUMMARY")

print(f"\n Dataset Info:")
print(f"Total test samples: {len(df_final)}")
print(f"Accuracy: {df_final['is_correct'].mean():.2%}")
print(f"Average confidence: {df_final['confidence'].mean():.2%}")

print(f"\n Sentiment Distribution:")
sentiment_dist = df_final['predicted_sentiment'].value_counts()
print(sentiment_dist)

print(f"\n Rating Distribution:")
rating_dist = df_final['rating'].value_counts().sort_index()
print(rating_dist)

print(f"\n Confusion Matrix:")
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(
    df_final['true_sentiment'],
    df_final['predicted_sentiment'],
    labels=['Positive', 'Neutral', 'Negative']
)
cm_df = pd.DataFrame(
    cm,
    index=['True_Positive', 'True_Neutral', 'True_Negative'],
    columns=['Pred_Positive', 'Pred_Neutral', 'Pred_Negative']
)
print(cm_df)

print(f"\n Sample Data:")
display(df_final.head(10))

# Download
from google.colab import files
files.download(output_path)

print("\n Done!")

def predict_scores(texts, tokenizer, model, max_len=128, batch_size=16):
    model.eval()
    scores = []

    # Get the model's device
    device = model.device if hasattr(model, 'device') else ('cuda' if torch.cuda.is_available() else 'cpu')

    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]

        enc = tokenizer(
            batch,
            padding=True,
            truncation=True,
            max_length=max_len,
            return_tensors="pt"
        )

        # Move input tensors to the same device as the model
        enc = {key: val.to(device) for key, val in enc.items()}

        with torch.no_grad():
            outputs = model(**enc)
            probs = torch.softmax(outputs.logits, dim=1)
            # Use LABEL2ID to get the correct index for Positive sentiment
            # LABEL2ID maps 'Positive' to its integer index
            positive_idx = LABEL2ID['Positive']
            pos_scores = probs[:, positive_idx].cpu().numpy()

        scores.extend(pos_scores)

    return np.array(scores)

df["accessibility_score"] = predict_scores(
    df["review_text"].tolist(),
    tokenizer,
    model
)

df["accessibility"] = df["accessibility_score"].apply(map_accessibility)

df["facilities"] = df["review_text"].apply(extract_facilities)

final_df = df[[
    "place_name",
    "rating",
    "accessibility",
    "facilities"
]].drop_duplicates()

# Save to csv
final_df.to_csv("tourism_accessibility_output.csv", index=False)

import matplotlib.pyplot as plt
import seaborn as sns

sns.set_style("whitegrid")
plt.rcParams['fig ure.figsize'] = (14, 8)
plt.rcParams['font.size'] = 10

print("Loading results...")
df_results = pd.read_csv('/content/drive/MyDrive/thesis/absa_detailed_results_v2.csv')

print(f"Total predictions: {len(df_results)}")
print(f"\nSentiment distribution:")
print(df_results['sentiment'].value_counts())

print("\nCalculating place rankings...")

# Aggregate by place
place_summary = (
    df_results
    .groupby(['place_name', 'sentiment'])
    .size()
    .unstack(fill_value=0)
)

# Calculate metrics
place_summary['Total_Reviews'] = place_summary.sum(axis=1)
place_summary['Positive'] = place_summary.get('Positive', 0)
place_summary['Negative'] = place_summary.get('Negative', 0)
place_summary['Neutral'] = place_summary.get('Neutral', 0)

# Accessibility Score: Positive - Negative
place_summary['Accessibility_Score'] = (
    place_summary['Positive'] - place_summary['Negative']
)

# Positive Percentage
place_summary['Positive_Pct'] = (
    place_summary['Positive'] / place_summary['Total_Reviews'] * 100
).round(2)

# Accessibility Rating (0-5 scale)
place_summary['Rating'] = (
    (place_summary['Positive_Pct'] / 20)  # 0-100% -> 0-5
).round(2)

# Sort by score
place_summary = place_summary.sort_values('Accessibility_Score', ascending=False)

# Add rank
place_summary['Rank'] = range(1, len(place_summary) + 1)

# Reorder columns for better display
place_summary = place_summary[[
    'Rank', 'Total_Reviews', 'Positive', 'Neutral', 'Negative',
    'Accessibility_Score', 'Positive_Pct', 'Rating'
]]

print("ACCESSIBILITY RANKING OF TOURIST PLACES")
print(place_summary.to_string())

# Export to CSV
place_summary.to_csv('/content/drive/MyDrive/thesis/accessibility_ranking.csv')
print(f"\n Ranking saved to: /content/drive/MyDrive/thesis/accessibility_ranking.csv")

fig, ax = plt.subplots(figsize=(14, 8))

top_15 = place_summary.head(15)
x = np.arange(len(top_15))
width = 0.25

bars1 = ax.bar(x - width, top_15['Positive'], width, label='Positive', color='#2ecc71')
bars2 = ax.bar(x, top_15['Neutral'], width, label='Neutral', color='#95a5a6')
bars3 = ax.bar(x + width, top_15['Negative'], width, label='Negative', color='#e74c3c')

ax.set_xlabel('Tourist Place', fontsize=12, fontweight='bold')
ax.set_ylabel('Number of Reviews', fontsize=12, fontweight='bold')
ax.set_title('Top 15 Most Accessible Places - Sentiment Distribution',
             fontsize=14, fontweight='bold', pad=20)
ax.set_xticks(x)
ax.set_xticklabels(top_15.index, rotation=45, ha='right')
ax.legend(loc='upper right', fontsize=11)
ax.grid(axis='y', alpha=0.3)

# Add value labels on bars
for bars in [bars1, bars2, bars3]:
    for bar in bars:
        height = bar.get_height()
        if height > 0:
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{int(height)}',
                   ha='center', va='bottom', fontsize=8)

plt.tight_layout()
plt.savefig('/content/drive/MyDrive/thesis/top_15_accessible_places.png', dpi=300, bbox_inches='tight')
plt.show()

print(" Chart saved: top_15_accessible_places.png")

fig, ax = plt.subplots(figsize=(14, 10))

# Create color map: green for positive, red for negative
colors = ['#2ecc71' if score > 0 else '#e74c3c' for score in place_summary['Accessibility_Score']]

ax.barh(place_summary.index, place_summary['Accessibility_Score'], color=colors, alpha=0.8)
ax.axvline(x=0, color='black', linestyle='-', linewidth=0.8)

ax.set_xlabel('Accessibility Score (Positive - Negative)', fontsize=12, fontweight='bold')
ax.set_ylabel('Tourist Place', fontsize=12, fontweight='bold')
ax.set_title('Wheelchair Accessibility Score by Place',
             fontsize=14, fontweight='bold', pad=20)
ax.grid(axis='x', alpha=0.3)

# Add value labels
for idx, (place, score) in enumerate(place_summary['Accessibility_Score'].items()):
    ax.text(score + (1 if score > 0 else -1), idx,
           f'{int(score)}',
           ha='left' if score > 0 else 'right',
           va='center',
           fontsize=8)

plt.tight_layout()
plt.savefig('/content/drive/MyDrive/thesis/accessibility_score_all_places.png', dpi=300, bbox_inches='tight')
plt.show()

print("Chart saved: accessibility_score_all_places.png")

fig, ax = plt.subplots(figsize=(12, 6))

ratings = place_summary['Rating']
ax.hist(ratings, bins=20, color='#3498db', alpha=0.7, edgecolor='black')

ax.set_xlabel('Accessibility Rating (0-5)', fontsize=12, fontweight='bold')
ax.set_ylabel('Number of Places', fontsize=12, fontweight='bold')
ax.set_title('Distribution of Accessibility Ratings',
             fontsize=14, fontweight='bold', pad=20)
ax.axvline(ratings.mean(), color='red', linestyle='--', linewidth=2,
          label=f'Mean: {ratings.mean():.2f}')
ax.axvline(ratings.median(), color='green', linestyle='--', linewidth=2,
          label=f'Median: {ratings.median():.2f}')
ax.legend(fontsize=11)
ax.grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.savefig('/content/drive/MyDrive/thesis/rating_distribution.png', dpi=300, bbox_inches='tight')
plt.show()

print("Chart saved: rating_distribution.png")

fig, ax = plt.subplots(figsize=(10, 8))

sentiment_counts = df_results['sentiment'].value_counts()
colors_pie = {'Positive': '#2ecc71', 'Neutral': '#95a5a6', 'Negative': '#e74c3c'}
colors_list = [colors_pie[sent] for sent in sentiment_counts.index]

wedges, texts, autotexts = ax.pie(
    sentiment_counts.values,
    labels=sentiment_counts.index,
    colors=colors_list,
    autopct='%1.1f%%',
    startangle=90,
    textprops={'fontsize': 12, 'fontweight': 'bold'}
)

for autotext in autotexts:
    autotext.set_color('white')
    autotext.set_fontsize(14)
    autotext.set_fontweight('bold')

ax.set_title('Overall Sentiment Distribution\nfor Wheelchair Accessibility',
             fontsize=14, fontweight='bold', pad=20)

plt.tight_layout()
plt.savefig('/content/drive/MyDrive/thesis/overall_sentiment_pie.png', dpi=300, bbox_inches='tight')
plt.show()

print("Chart saved: overall_sentiment_pie.png")

if 'aspect_type' in df_results.columns:
    fig, ax = plt.subplots(figsize=(12, 6))

    aspect_sentiment = df_results.groupby(['aspect_type', 'sentiment']).size().unstack(fill_value=0)

    aspect_sentiment.plot(
        kind='bar',
        stacked=False,
        color=['#e74c3c', '#95a5a6', '#2ecc71'],
        ax=ax,
        width=0.8
    )

    ax.set_xlabel('Aspect Type', fontsize=12, fontweight='bold')
    ax.set_ylabel('Number of Mentions', fontsize=12, fontweight='bold')
    ax.set_title('Sentiment Distribution by Aspect Type',
                 fontsize=14, fontweight='bold', pad=20)
    ax.legend(title='Sentiment', fontsize=10)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')
    ax.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.savefig('/content/drive/MyDrive/thesis/sentiment_by_aspect_type.png', dpi=300, bbox_inches='tight')
    plt.show()

    print("Chart saved: sentiment_by_aspect_type.png")

fig, ax = plt.subplots(figsize=(12, 6))

for sentiment in ['Positive', 'Neutral', 'Negative']:
    data = df_results[df_results['sentiment'] == sentiment]['confidence']
    ax.hist(data, bins=30, alpha=0.6, label=sentiment,
           color=colors_pie[sentiment], edgecolor='black')

ax.set_xlabel('Confidence Score', fontsize=12, fontweight='bold')
ax.set_ylabel('Frequency', fontsize=12, fontweight='bold')
ax.set_title('Prediction Confidence Distribution by Sentiment',
             fontsize=14, fontweight='bold', pad=20)
ax.legend(fontsize=11)
ax.grid(axis='y', alpha=0.3)
ax.axvline(0.5, color='red', linestyle='--', linewidth=2,
          label='Confidence Threshold (50%)')

plt.tight_layout()
plt.savefig('/content/drive/MyDrive/thesis/confidence_distribution.png', dpi=300, bbox_inches='tight')
plt.show()

print("Chart saved: confidence_distribution.png")